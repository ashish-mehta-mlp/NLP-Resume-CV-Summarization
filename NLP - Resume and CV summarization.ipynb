{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collecting Training Data can be incredibly painful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For training data (how to prepare nlp training data): https://spacy.io/usage/training#training-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open(\"C:/Users/Ashish/Desktop/Python Projects/CV and Resume Summarization (NLP)/train_data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
       " {'entities': [(1749, 1755, 'Companies worked at'),\n",
       "   (1696, 1702, 'Companies worked at'),\n",
       "   (1417, 1423, 'Companies worked at'),\n",
       "   (1356, 1793, 'Skills'),\n",
       "   (1209, 1215, 'Companies worked at'),\n",
       "   (1136, 1248, 'Skills'),\n",
       "   (928, 932, 'Graduation Year'),\n",
       "   (858, 889, 'College Name'),\n",
       "   (821, 856, 'Degree'),\n",
       "   (787, 791, 'Graduation Year'),\n",
       "   (744, 750, 'Companies worked at'),\n",
       "   (722, 742, 'Designation'),\n",
       "   (658, 664, 'Companies worked at'),\n",
       "   (640, 656, 'Designation'),\n",
       "   (574, 580, 'Companies worked at'),\n",
       "   (555, 573, 'Designation'),\n",
       "   (470, 493, 'Companies worked at'),\n",
       "   (444, 469, 'Designation'),\n",
       "   (308, 314, 'Companies worked at'),\n",
       "   (234, 240, 'Companies worked at'),\n",
       "   (175, 198, 'Companies worked at'),\n",
       "   (93, 137, 'Email Address'),\n",
       "   (39, 48, 'Location'),\n",
       "   (13, 38, 'Designation'),\n",
       "   (0, 12, 'Name')]})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def train_model(train_data):\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  #Only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(10):\n",
    "            print(\"Starting Iteration \" + str(itn))\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            index = 0\n",
    "            for text, annotations in train_data:\n",
    "                # print index\n",
    "                try:\n",
    "                    nlp.update(\n",
    "                        [text], #batch of texts\n",
    "                        [annotations], #batch of annotations\n",
    "                        drop = 0.2, #dropout - make it harder to memorize \n",
    "                        sgd = optimizer, #callable to update weights\n",
    "                        losses = losses)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                      #print(text)\n",
    "                    \n",
    "            print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Iteration 0\n",
      "{'ner': 14612.719882360358}\n",
      "Starting Iteration 1\n",
      "{'ner': 9009.208793745103}\n",
      "Starting Iteration 2\n",
      "{'ner': 10675.988715216505}\n",
      "Starting Iteration 3\n",
      "{'ner': 6225.49919928082}\n",
      "Starting Iteration 4\n",
      "{'ner': 6054.286762662675}\n",
      "Starting Iteration 5\n",
      "{'ner': 6323.285963396171}\n",
      "Starting Iteration 6\n",
      "{'ner': 5541.298066961361}\n",
      "Starting Iteration 7\n",
      "{'ner': 5744.006587369071}\n",
      "Starting Iteration 8\n",
      "{'ner': 4350.9219955215685}\n",
      "Starting Iteration 9\n",
      "{'ner': 4388.279996247049}\n"
     ]
    }
   ],
   "source": [
    "train_model(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the NLP model for Future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"nlp_CVmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the saved NLP trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model = spacy.load(\"nlp_CVmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Sanand Pal SQL and MSBI Developer with experience in Azure SQL and Data Lake store.  Hyderabad, Telangana - Email me on Indeed: indeed.com/r/Sanand-Pal/5c99c42c3400737c  I intend to establish myself as Software Engineer / architect with an integrated business solution provider through a long time commitment, contributing to the company's growth and in turn ensuring personal growth within the organization. I believe that my technical, functional and communication skills will enable me in facing the challenging career ahead.  Willing to relocate to: Kolkata, West Bengal - hyderbad, Telangana  WORK EXPERIENCE  Assistant Consultant  TCS  • Expertise in SQL Server(2008 R2, 2012, 2014) development, Microsoft BI (SSIS) • Experience with Microsoft BI (SSAS, SSRS), ASP.NET, VSTO, C#. • Experience in all the phases of Software Development Life Cycle (SDLC). • Experience in Business Requirements Analysis, meeting customer expectations. • Have had the opportunity to handle and work in multiple projects at a time. • Experience in working both independently and in a team-oriented, collaborative environment. • Excellent written and verbal communication skills, good analytical and problem solving skills.  SQL and SSIS developer/Sustain resource  MICROSOFT -  Hyderabad, Telangana -  August 2011 to June 2016  Project US EPG Forecast Workbook (FWB) application is designed to support the US Enterprise Partner Group (US EPG) in producing and maintaining the monthly US sales forecast. It is a transactional database combined with Microsoft Office Excel functionality that enables end users to interact with the USNAForecast database. Typically, an ATU manager will connect to the corporate network and download data from the forecast database, which creates an offline forecast workbook. This data can then be accessed offline, modelled, and changes to certain data fields are subsequently uploaded back to the forecast database through a CorpNet connection. These changes are then stored in the online database and subsequently loaded back into upstream systems.  Responsibilities • Involved in the Technical discussions/Sessions and efforts estimations and reviews. • Involved in analysis of the Bugs/ Issues/defects/CRs. • Involved in change requests on VSTO Excel application. • Involved in design of database, tables and stored procedures. • Developed SQL Server Integration Services packages for ETL process. • Unit testing and bug fixing of the code.  https://www.indeed.com/r/Sanand-Pal/5c99c42c3400737c?isid=rex-download&ikw=download-top&co=IN   • Actively solved the issues that raised during the integration cycle • Performed build verification and Smoke tested all the defects raised before giving a delivery. • Prepared and updated FS, TS and deployment guides. • Provided knowledge sharing to Users • Provided post implementation support • Promptly check in the final Code in VSTF.  Hyderabad, India  EDUCATION  Bachelor of Technology in Branch  East Point College of Engg. & Tech. -  Bengaluru, Karnataka  June 2006 to July 2010  SKILLS  Sql Server, Ssis, T-SQL, ETL, SSRS\",\n",
       " {'entities': [(3056, 3090, 'Skills'),\n",
       "   (3042, 3046, 'Graduation Year'),\n",
       "   (2963, 2998, 'College Name'),\n",
       "   (2929, 2961, 'Degree'),\n",
       "   (2900, 2910, 'Location'),\n",
       "   (2474, 2514, 'Email Address'),\n",
       "   (1263, 1273, 'Location'),\n",
       "   (636, 640, 'Companies worked at'),\n",
       "   (615, 635, 'Designation'),\n",
       "   (128, 168, 'Email Address'),\n",
       "   (85, 95, 'Location'),\n",
       "   (11, 33, 'Designation'),\n",
       "   (0, 10, 'Name')]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It not a good idea to test the model with training data.\n",
    "- But for understanding purposes, we pass the above training data to our nlp model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          -Sanand Pal\n",
      "DESIGNATION                   -SQL and MSBI Developer\n",
      "LOCATION                      -Hyderabad\n",
      "EMAIL ADDRESS                 -indeed.com/r/Sanand-Pal/5c99c42c3400737c\n",
      "LOCATION                      -Kolkata\n",
      "DESIGNATION                   -Assistant Consultant\n",
      "COMPANIES WORKED AT           -TCS\n",
      "COMPANIES WORKED AT           -Microsoft\n",
      "DESIGNATION                   -SSIS developer/Sustain resource\n",
      "COMPANIES WORKED AT           -MICROSOFT\n",
      "LOCATION                      -Hyderabad\n",
      "LOCATION                      -Hyderabad\n",
      "DEGREE                        -Bachelor of Technology in Branch\n",
      "COLLEGE NAME                  -East Point College of Engg. & Tech.\n",
      "LOCATION                      -Bengaluru\n",
      "SKILLS                        -Sql Server, Ssis, T-SQL, ETL, SSRS\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_model(train_data[0][0]) # loading only the text data and not the entities.\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.label_.upper():{30}}-{ent.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Classification on an unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Steps:\n",
    "    1. Convert the pdf to text format\n",
    "    2. Get all the text from text formatted data\n",
    "    3. Perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading https://files.pythonhosted.org/packages/19/1a/aa35448efb2ec495b515030684f60ba1ea805c314f0109740df04d060d17/PyMuPDF-1.16.17-cp37-cp37m-win_amd64.whl (4.9MB)\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.16.17\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, fitz\n",
    "fname = \"Alice Clark CV.pdf\"\n",
    "doc = fitz.open(fname)\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text = text + str(page.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Clark \n",
      "AI / Machine Learning \n",
      " \n",
      "Delhi, India Email me on Indeed \n",
      "• \n",
      "20+ years of experience in data handling, design, and development \n",
      "• \n",
      "Data Warehouse: Data analysis, star/snow flake scema data modelling and design specific to \n",
      "data warehousing and business intelligence \n",
      "• \n",
      "Database: Experience in database designing, scalability, back-up and recovery, writing and \n",
      "optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes. \n",
      "Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure, \n",
      "Stream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake \n",
      "analytics(U-SQL) \n",
      "Willing to relocate anywhere \n",
      " \n",
      "WORK EXPERIENCE \n",
      "Software Engineer \n",
      "Microsoft – Bangalore, Karnataka \n",
      "January 2000 to Present \n",
      "1. Microsoft Rewards Live dashboards: \n",
      "Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping \n",
      "online. Microsoft Rewards members can earn points when searching with Bing, browsing with \n",
      "Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft \n",
      "Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft \n",
      "rewards website. Rewards live dashboards gives a live picture of usage world-wide and by \n",
      "markets like US, Canada, Australia, new user registration count, top/bottom performing rewards \n",
      "offers, orders stats and weekly trends of user activities, orders and new user registrations. the \n",
      "PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes. \n",
      "Technology/Tools used \n",
      " \n",
      "EDUCATION \n",
      "Indian Institute of Technology – Mumbai \n",
      "2001 \n",
      " \n",
      "SKILLS \n",
      "Machine Learning, Natural Language Processing, and Big Data Handling \n",
      " \n",
      "ADDITIONAL INFORMATION \n",
      "Professional Skills \n",
      "• Excellent analytical, problem solving, communication, knowledge transfer and interpersonal \n",
      "skills with ability to interact with individuals at all the levels \n",
      "• Quick learner and maintains cordial relationship with project manager and team members and \n",
      "good performer both in team and independent job environments \n",
      "• Positive attitude towards superiors &amp; peers \n",
      "• Supervised junior developers throughout project lifecycle and provided technical assistance \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing new lines that are present in the above text\n",
    "\n",
    "tx = \" \".join(text.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Clark  AI / Machine Learning    Delhi, India Email me on Indeed  •  20+ years of experience in data handling, design, and development  •  Data Warehouse: Data analysis, star/snow flake scema data modelling and design specific to  data warehousing and business intelligence  •  Database: Experience in database designing, scalability, back-up and recovery, writing and  optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes.  Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure,  Stream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake  analytics(U-SQL)  Willing to relocate anywhere    WORK EXPERIENCE  Software Engineer  Microsoft – Bangalore, Karnataka  January 2000 to Present  1. Microsoft Rewards Live dashboards:  Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping  online. Microsoft Rewards members can earn points when searching with Bing, browsing with  Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft  Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft  rewards website. Rewards live dashboards gives a live picture of usage world-wide and by  markets like US, Canada, Australia, new user registration count, top/bottom performing rewards  offers, orders stats and weekly trends of user activities, orders and new user registrations. the  PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.  Technology/Tools used    EDUCATION  Indian Institute of Technology – Mumbai  2001    SKILLS  Machine Learning, Natural Language Processing, and Big Data Handling    ADDITIONAL INFORMATION  Professional Skills  • Excellent analytical, problem solving, communication, knowledge transfer and interpersonal  skills with ability to interact with individuals at all the levels  • Quick learner and maintains cordial relationship with project manager and team members and  good performer both in team and independent job environments  • Positive attitude towards superiors &amp; peers  • Supervised junior developers throughout project lifecycle and provided technical assistance  \n"
     ]
    }
   ],
   "source": [
    "print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          - Alice Clark\n",
      "DESIGNATION                   - AI / Machine Learning\n",
      "LOCATION                      - Delhi\n",
      "DESIGNATION                   - Software Engineer\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "LOCATION                      - Bangalore\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "COMPANIES WORKED AT           - Microsoft\n",
      "DEGREE                        - Indian Institute of Technology\n",
      "COLLEGE NAME                  - Mumbai\n",
      "SKILLS                        - Machine Learning, Natural Language Processing, and Big Data Handling    ADDITIONAL INFORMATION  Professional Skills\n"
     ]
    }
   ],
   "source": [
    "# testing the model on unseen data\n",
    "\n",
    "doc = nlp_model(tx)\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.label_.upper():{30}}- {ent.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
